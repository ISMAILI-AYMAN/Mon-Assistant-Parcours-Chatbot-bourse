import streamlit as st
from langchain_chroma import Chroma
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import ChatOllama
from ingest import main

# Initialisation de la base de donn√©es
if "db" not in st.session_state:
    st.session_state.db = main()  

# Initialisation de l'historique des messages
if "messages" not in st.session_state:
    st.session_state.messages = []

# Fonction pour r√©cup√©rer des r√©ponses depuis la base de donn√©es
def retrieve_from_db(question):
    model = ChatOllama(model="mistral")
    retriever = st.session_state.db.similarity_search(question, k=5)

    after_rag_template = """Tu es un assistant sp√©cialis√© dans les parcours de bourses d'√©tudes. Ton r√¥le est d'aider les utilisateurs √† trouver les opportunit√©s de bourses les plus adapt√©es √† leur profil. 
    Tout en agissant comme un conseiller et un guide personnalis√©. Tu ne r√©ponds qu'en fran√ßais.
    Contexte : {context}
    Question : {question}"""

    after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)

    after_rag_chain = (
        {"context": RunnablePassthrough(), "question": RunnablePassthrough()}
        | after_rag_prompt
        | model
        | StrOutputParser()
    )

    return after_rag_chain.invoke({"context": retriever, "question": question})


# Configuration de la page Streamlit
st.set_page_config(page_title="üéì Assistant Bourses d'√âtudes", layout="wide")

# Sidebar pour l'historique des questions
st.sidebar.title("üí¨ Historique des Questions")
if st.session_state.messages:
    for i, msg in enumerate(st.session_state.messages):
        if msg["user"] == "user":
            st.sidebar.write(f"üîπ {i+1}. {msg['content']}")

# Titre principal
st.title("üéì Assistant Parcours de Bourses d'√âtudes")

# Affichage des messages
st.write("**Discussion**")
for msg in st.session_state.messages:
    if msg["user"] == "user":
        st.markdown(
            f"""
            <div style="display: flex; justify-content: flex-end; margin-bottom: 10px;">
                <div style="background-color: #0078D4; color: white; padding: 10px; border-radius: 10px; max-width: 60%; text-align: left;">
                    {msg['content']}
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            f"""
            <div style="display: flex; justify-content: flex-start; margin-bottom: 10px;">
                <div style="background-color: #444444; color: white; padding: 10px; border-radius: 10px; max-width: 60%; text-align: left;">
                    {msg['content']}
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

# Zone de saisie utilisateur avec possibilit√© d'aller √† la ligne
question = st.text_area("Posez votre question ici :", "", height=100, placeholder="Tapez votre question...")

# Bouton d'envoi avec une ic√¥ne de fl√®che
send_button = st.button("Envoyer ", use_container_width=True)

# Gestion des r√©ponses
if send_button and question.strip():
    # Ajout de la question √† l'historique
    st.session_state.messages.append({"user": "user", "content": question.strip()})
    
    # G√©n√©ration de la r√©ponse
    with st.spinner("L'Assistant r√©dige sa r√©ponse..."):
        try:
            answer = retrieve_from_db(question.strip())
        except Exception as e:
            answer = "Je suis d√©sol√©, une erreur est survenue. Veuillez r√©essayer plus tard."
    
    # Ajout de la r√©ponse √† l'historique
    st.session_state.messages.append({"user": "bot", "content": answer})
    
    # Efface la zone de saisie
    st.text_area("Posez votre question ici :", "", key="question", height=100)
